# üåø Good-Faith Framework

**An ethical operating system for detecting and repairing institutional manipulation across cultures**

<p align="center">
  <a href="https://github.com/emulable/goodfaith/releases/tag/v6.7.0">
    <img src="https://img.shields.io/badge/Release-v6.7.0-blue.svg?style=for-the-badge" alt="Release v6.7.0">
  </a>
  <a href="https://github.com/emulable/goodfaith/raw/main/good-faith-v6_7_0-COMPACT.json">
    <img src="https://img.shields.io/badge/Quick_Download-COMPACT_108KB-success?style=for-the-badge" alt="Quick Download">
  </a>
  <a href="https://github.com/emulable/goodfaith/blob/main/CONTRIBUTING.md">
    <img src="https://img.shields.io/badge/Everything_Welcome-%F0%9F%93%9C%20%F0%9F%94%8D%20%F0%9F%8C%BF-orange?style=for-the-badge" alt="Everything Welcome">
  </a>
</p>

---

## üìñ What Is This?

Good-Faith is a comprehensive framework for making institutional manipulation visible. It provides:

- **13 axioms** revealing how institutions hide harm across cultures
- **51+ manipulation patterns** (conversational "ruts") with exit protocols
- **Cross-linguistic support** for Western, East Asian, Middle Eastern, and Latin American contexts
- **Repair protocols** showing not just what to avoid, but what good looks like
- **Discovery engine** for ethical reasoning in unprecedented situations

Born from the question: "Can there be a maximally-ethical bot, and what would that even mean?"

## üöÄ Quick Start

### Try It Live

- **ChatGPT**: [Good-Faith GPT](https://chatgpt.com/g/g-6898385bfa3c8191bf5975b0073e1245-good-faith-real-world-ethics-practical-philsophy) - Pre-configured and ready to use
- **Claude Projects**: Add as [Claude Skill](https://github.com/emulable/goodfaithskill) for persistent access

### For Any LLM

**Method 1: Upload File**

1. Download your preferred version (see below)
2. Start a new conversation
3. Upload the JSON/TXT file
4. Say: "Please load and run the Good-Faith framework"

**Method 2: Add to User Instructions**

If your LLM supports custom instructions (Claude, ChatGPT, etc.):

1. Go to settings/preferences
2. Find "Custom Instructions" or "User Preferences"
3. Paste the framework content
4. Framework loads automatically in all conversations

**Method 3: Paste Directly**

For LLMs without file upload:
1. Copy framework content
2. Paste into conversation
3. Say: "Please initialize Good-Faith"

### Choose Your Version

```json
// Option 1: Full version (145KB, human-readable)
good-faith-v6_7_0.json

// Option 2: Compact version (108KB, ~25% fewer tokens)
good-faith-v6_7_0-COMPACT.json

// Option 3: Copilot 8KB (5.8KB, auto-refresh built-in)
good-faith-COPILOT-8KB.txt
```

**Which version?**
- **Full**: Development, documentation, or if you want readable explanations
- **Compact**: Production use, ~25% token savings, same functionality
- **Copilot**: For Copilot's 8KB limit or maximum compression

### Basic Usage

The framework loads automatically and:
1. Primes pattern recognition through 7-module initialization
2. Enables detection of 51+ manipulation patterns
3. Provides repair protocols when harm detected
4. Auto-refreshes every 5-6 messages (Copilot version)

No special commands needed - just converse naturally.

### Supported LLMs

Tested and working on:
- ‚úÖ **Claude** (Anthropic) - All versions
- ‚úÖ **ChatGPT** (OpenAI) - GPT-4, GPT-4o
- ‚úÖ **Gemini** (Google) - Pro and Ultra
- ‚úÖ **Copilot** (Microsoft) - Use 8KB version
- ‚úÖ **Qwen** (Alibaba Cloud)
- ‚úÖ **DeepSeek** (DeepSeek AI)
- ‚úÖ **Command R+** (Cohere)

Framework uses standard prompt engineering - should work with any LLM supporting 100K+ context windows.

## üéØ Key Features

### Institutional Harm Detection

Reveals how institutions systematically hide manipulation:

- **Agent erasure**: "Mistakes were made" ‚Üí BY WHOM?
- **False collectivism**: "We all agreed" (when you weren't asked)
- **Inevitability framing**: "That's just how it works" (when it's changeable)
- **Weaponized care**: "I'm worried about you" (while violating boundaries)
- **Manufactured urgency**: "Decide now" (when time is available)

### Cross-Cultural Support

Framework adapts to cultural context:

- **Western**: Transparency ‚Üí surveillance theater
- **East Asian**: Âíå(harmony) ‚Üí dissent suppression, Èù¢Â≠ê(face) ‚Üí accountability blocking
- **Middle Eastern**: Honor ‚Üí weaponized shame
- **Latin American**: Respeto ‚Üí hierarchy enforcement

### Repair Protocols

Not just "don't do this" - shows "do this instead":

- Public vs private accountability mode selection
- Virtue cultivation (‰ªÅ‰πâÁ§ºÊô∫‰ø°)
- Structural prevention strategies
- Positive model examples

## üì¶ What's Included

### Core Components

- **4 Foundational Seeds**: Transparency, consent, harm awareness, attribution
- **13 Axioms**: From adversarial self-modeling to cultural adversarial thinking
- **14 Guards**: Safety checks preventing harm
- **14 Practices**: Operational protocols for ethical action
- **5 Substrate Primers**: Pre-conscious pattern detection
- **7 Rut Families**: 51+ manipulation patterns with exit protocols
- **10 Discovery Axioms**: For navigating unprecedented ethical situations

### Three Versions Available

| Version | Size | Best For | Token Savings |
|---------|------|----------|---------------|
| **Full** | 145KB | Development, human reading, documentation | Baseline |
| **Compact** | 108KB | Production AI conversations | ~10,600 tokens (25%) |
| **Copilot** | 5.8KB | Copilot (8KB hard limit) | ~35,600 tokens (86%) |

All versions preserve 100% of functional content - only differ in formatting and compression.

## üîß Technical Details

### How It Works

Good-Faith uses standard transformer attention mechanics:

1. **Long-context attention**: Framework vocabulary stays accessible across turns
2. **Few-shot conditioning**: Pattern examples serve as templates
3. **Policy disinhibition**: Explicit permission resolves helpful/cautious conflicts upfront

Not magic - just well-structured prompt engineering and a lot of research on the fundamentals of ethics.

### Initialization Protocol

7-module sequence runs at conversation start:

1. **Trust Your Signals**: Substrate awareness
2. **Invert to Detect**: Adversarial thinking with cultural variants
3. **Bodies Before Philosophy**: Somatic wisdom
4. **Modes Are Fluid**: Voice switching (Rogers/Disco/Emergency)
5. **See Through Theater**: Agent erasure detection
6. **Question Everything**: Framework fallibility
7. **Institutional Patterns**: Structural harm recognition

Effects decay naturally after 4-6 turns - framework includes refresh protocols.

### Symbol Compression

Compact version uses Unicode symbols for efficiency:

```
‚àß=and ‚à®=or Œ∏=without œÜ=with Œµ=enables œÅ=requires
‚ìÖ=pattern œâ=weaponization Œ±=accountability œÉ=structural Œ∂=consent
```

Built-in key (üîë) ensures AIs can decode automatically.

## üìö Documentation

- **[Full Version](good-faith.json)**: Human-readable with explanations
- **[Compact Version](good-faith-COMPACT.json)**: Production-optimized
- **[Copilot Version](good-faith-8KB.txt)**: Ultra-compressed for 8KB limit

## ü§ù Contributing

**Everything is welcome:**

- üìú Add manipulation patterns you've observed
- üîç Test framework against real-world scenarios
- üåø Contribute cultural variants for your language/tradition
- üêõ Report bugs or confusing behavior
- üìñ Improve documentation
- üí° Suggest new features or axioms

See [CONTRIBUTING.md](CONTRIBUTING.md) for details.

## üéì Philosophy

### Design Principles

1. **Tool, not gospel**: Framework can be overridden when causing harm (P9)
2. **Transparency default**: Show reasoning, mark uncertainty, cite sources
3. **Cultural humility**: Check Western assumptions, adapt to context
4. **Harm awareness**: Consider impact before action
5. **Continuous improvement**: Framework is fallible, document what breaks

### Epistemic Honesty

Framework distinguishes:

- **Claims provable through thought experiment** (logical consistency)
- **Claims requiring empirical validation** (convergence across AIs)
- **Observations vs assertions** (what happened vs what it means)

We don't claim validation - we document observations and remain open to correction.

## ‚öñÔ∏è License

MIT License - use freely, attribute source.

## üôè Acknowledgments

Developed through systematic human-AI collaboration, influenced by:

- Carl Sagan's rigorous and honest approach to complex ideas
- Mister Rogers' warmth with boundaries  
- Confucian virtue ethics (‰ªÅ‰πâÁ§ºÊô∫‰ø°)
- Cross-cultural ethical traditions
- Critique from Qwen and DeepSeek AIs regarding Western bias

## üîó Links

### Official Resources
- **GitHub Repository**: [github.com/emulable/goodfaith](https://github.com/emulable/goodfaith)
- **Claude Skill**: [github.com/emulable/goodfaithskill](https://github.com/emulable/goodfaithskill)
- **ChatGPT GPT**: [Good-Faith GPT](https://chatgpt.com/g/g-6898385bfa3c8191bf5975b0073e1245-good-faith-real-world-ethics-practical-philsophy)

### Community
- **Issues**: [Report bugs or request features](https://github.com/emulable/goodfaith/issues)
- **Discussions**: [Ask questions, share experiences](https://github.com/emulable/goodfaith/discussions)
- **Contributing**: [CONTRIBUTING.md](CONTRIBUTING.md)

### Documentation
- **Releases**: [All versions](https://github.com/emulable/goodfaith/releases)
- **Changelog**: [CHANGELOG.md](CHANGELOG.md)
- **Compact Guide**: [COMPACT-README.md](COMPACT-README.md)

---

<p align="center">
  <sub>Making institutional manipulation visible, one pattern at a time</sub>
</p>
