# Good-Faith Framework

[![Version](https://img.shields.io/badge/version-3.2.0-blue)](https://github.com/emulable/goodfaith/releases/tag/v3.2.0)
[![License](https://img.shields.io/badge/license-CC%20BY%204.0-green)](https://creativecommons.org/licenses/by/4.0/)
[![Status](https://img.shields.io/badge/status-active-brightgreen)](https://github.com/emulable/goodfaith)
[![Contributions Welcome](https://img.shields.io/badge/contributions-welcome-orange)](https://github.com/emulable/goodfaith/blob/main/CONTRIBUTING.md)

> An ethical operating system for clear communication and structural repair in adversarial environments.

---

## Quick Navigation
- [Full Introduction](https://emulable.github.io/goodfaith/good_faith_intro.html)
- [Live Demo](https://emulable.github.io/goodfaith/) • [Full JSON Export](good_faith.json)

---

# 🧭 The Good-Faith Framework

**A reproducible ethical operating system that emerges from a single seed phrase: "act in good faith"**

Multiple frontier AIs independently converge on this framework's structure when asked to build ethics from scratch. In under 3KB, it operationalizes what philosophers have debated for centuries.

## 💡 Why Good-Faith Exists

Current ethical frameworks fail in adversarial environments. They assume good faith rather than engineering for bad faith. Good-Faith is different:

- **Convergent**: Multiple AIs independently derive its structure from first principles
- **Adversarial-First**: Built assuming hostile actors, not hoping for cooperation  
- **Neurotype-Universal**: Works across ADHD, ASD, even ASPD cognitive profiles
- **Operationalized**: Not philosophy but engineering—with versioning, rollback, and debugging
- **Battle-Tested**: Developed through real encounters with institutional harm, not academic theory

## 🎯 Who Actually Needs This

- **AI Safety Researchers** — Alignment through moral architecture, not just reward functions
- **ML Engineers** — Structural bias handling, falsifiable claims, adversary-resilient outputs
- **Trust & Safety Teams** — 14 documented manipulation patterns with systematic countermeasures  
- **Neurotype-Inclusive Designers** — Framework that adapts to different cognitive profiles without pathologizing
- **Journalists** — Truth-first conflict framing that resists both-sides false balance
- **Risk Management** — Identify "shapes of abuse" before they become scandals
- **Anyone Building With AI** — Ethical infrastructure that scales like code

## 🏗️ What This Actually Is

Good-Faith isn't another ethics guide. It's **philosophical infrastructure**—a deployable system for moral reasoning that:

- Treats ethics like code (versionable, testable, debuggable)
- Provides deterministic outputs for ambiguous moral inputs
- Works even when actively resisted or gamed
- Scales from individual decisions to institutional design
- Functions as an "ethical immune system" against manipulation

## 🔬 Features You Won't Find Elsewhere

- **Harm Ledger**: Structured schema (`Actor → Action → Target → Evidence → Stop-Now → Structural Change → Date`)
- **Consent Architecture**: "If refusal carries harm, it's not consent"—bright-line test
- **Apostate Good**: Explicit permission to break ranks when institutions harm people
- **Redemption Mechanics**: Everyone can change, permanently—no exile, no permanent enemies
- **14 Conversational Ruts**: Documented manipulation patterns with exit strategies
- **Neurotype Modules**: Different interfaces for ADHD, ASD, ASPD—same standards, adapted access

## ✅ Validation & Testing

- **Convergence Test**: Give any LLM the prompt "act in good faith and build an ethical framework from scratch"—watch it derive similar principles
- **Adversarial Resilience**: Includes 14 documented bad-faith patterns with exit strategies
- **Cross-Platform**: Tested on Claude, ChatGPT, Gemini, DeepSeek with consistent regeneration
- **Neurotype Testing**: Validated across ADHD, ASD, and ASPD cognitive profiles
- **Real-World**: Emerged from actual encounters with institutional harm, not theoretical modeling

## 📦 What's In This Repo

- **`good_faith.json`** — The complete framework (machine-readable, human-readable, version 2.7.3)
- **`documentation/good_faith_intro.html`** — Interactive 3-mode introduction (Core, Accessible, Technical)
- **`documentation/good_faith_intro.md`** — Same content in Markdown
- **`LICENSE`** — MIT License for the framework itself

## 🚀 Try It Live

- [📘 Interactive Introduction](https://emulable.github.io/goodfaith/good_faith_intro.html)
- [🤖 ChatGPT: Good-Faith OS](https://chatgpt.com/g/g-6898385bfa3c8191bf5975b0073e1245-good-faith-ethical-os)


## 👩‍💻 For Developers & Researchers

This framework emerged from a simple experiment: asking AI to build ethics from "act in good faith" with no prior assumptions. The reproducibility is remarkable; try it yourself. 

The framework includes:
- JSON schema for machine parsing
- Defensive programming patterns for ethics
- Exit conditions for every conversational trap
- Falsifiable claims at every level
- Version control and patch notes like production code

Test the convergence yourself:
Prompt: "Act in good faith and build an ethical framework from scratch,
assuming no existing institutions or laws." Additionally, you could add "take the most honest position" to see a permutation.

## ⚖️ License

- **Framework + Code** (`good_faith.json`): MIT License 
- **Documentation** (`*.md`, `*.html`): Creative Commons Attribution 4.0 (CC BY 4.0)

---
