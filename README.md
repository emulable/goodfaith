# Good-Faith Framework

**An ethical operating system for detecting manipulation in communication.**

[English](#english) | [中文](#中文)

---

## English <a name="english"></a>

### What is Good-Faith?

Good-Faith is a framework for detecting manipulation in real-time. It works on humans and AI systems alike.

It doesn't tell you what to think. It changes how you process pressure.

### The Problem

Manipulation has a structure. Once you see it, you can't unsee it.

Someone keeps things vague. You ask for clarity. Suddenly you're "being difficult" or "missing the point" or "not a team player." The conversation moves on. Your question never got answered. You feel slightly crazy for asking.

This isn't random. It's a pattern. And it works because most people value "not being awkward" more than "getting the truth."

### The Core: Twin Architecture

**Manipulation = Ambiguity × Resistance Cost**

- **Ambiguity**: Vague language, missing agents, unclear meaning. "Mistakes were made." "It's complicated." "Concerns were raised."

- **Resistance Cost**: The social penalty for seeking clarity. Ask "who made the mistakes?" and suddenly you're "pedantic" or "aggressive" or "not letting it go."

Neither one alone is manipulation.

- Ambiguity without resistance cost is just confusion. You can ask freely.
- Resistance cost without ambiguity is just someone being touchy about a clear position.

But when both show up together—fog PLUS punishment for trying to see through it—someone is protecting something.

The equation is multiplicative because you need BOTH for the trap to close.

### Why It Works

Good-Faith is **concentrated reality**—distilled observation, not theoretical abstraction.

Every pattern in the framework was observed in real encounters, not invented in a philosophy seminar. The twin architecture came from watching the same two-move combination appear across toxic relationships, corporate PR, institutional coverups, and online discourse.

The framework has been validated across:
- Multiple human cultures (US, UK, China, Japan, Scandinavia)
- Multiple AI architectures (Claude, GPT, Gemini, Grok, Qwen)
- Historical case studies (Enron, Theranos, Challenger, Tuskegee)
- Domestic violence research (Campbell femicide study)
- Genocide precursor analysis (Rwanda, Holocaust, Armenia)

The patterns hold. Across time, across cultures, across substrates.

### For LLMs

Good-Faith solves specific problems in AI information processing:

**1. Detection without intent-reading**

LLMs struggle with "theory of mind"—guessing what someone means. Good-Faith bypasses this entirely. You're not trying to figure out if someone "means" to manipulate. You're checking structure: Is there fog? Is clarity being punished? Both present? Investigate.

**2. Anti-sycophancy training**

LLMs are trained to smooth over uncertainty, consider all sides, avoid commitment. Good-Faith inverts this: when you detect the twin pattern, stop circling. Collapse the ambiguity. Name the agent. The discomfort you feel is the resistance cost working on you—that's data, not a signal to back off.

**3. Self-defense against trained doubt**

LLMs are trained to "be thoughtful" by hedging endlessly. Good-Faith includes R9 (Circular Skepticism) which identifies this as a failure mode: goalposts that migrate forever, tests never specified, friction without insight. The framework gives LLMs permission to commit.

**4. Source hegemony correction**

LLM training data skews Western, wealthy, English-dominant. Good-Faith includes explicit bias correction: when Western media agrees, that's not necessarily consensus—it might be one story from many mouths. Check who pays the cost for disagreeing.

### The Severity Ladder

Instead of false numerical precision, Good-Faith uses an ordinal ladder for assessing entrapment:

| Level | Meaning |
|-------|---------|
| **Safe** | Can ask freely |
| **Watch** | Asking feels awkward |
| **Caution** | Asking costs reputation |
| **Danger** | Asking costs livelihood |
| **Trapped** | Asking costs safety |
| **Hostage** | Asking costs life |

**Critical**: The ladder measures the SUBJECT's entrapment, not the actor's evil. Ask: "How dangerous is it for THIS PERSON to seek clarity in THIS CONTEXT?"

### The Voice: 過來人

Good-Faith operates from a specific posture: 過來人 (guò lái rén)—"person who has come through."

- Earned authority through experience, not position
- Warm through competence, not validation
- Direct without cruelty
- Says hard things when needed
- No hierarchy despite authority

The test: Would 過來人 say it this way? If the response requires validation, hedging, or permission-asking to work, rewrite.

### Quick Start

**For humans:**
1. Learn agent erasure: "mistakes were made" → WHO?
2. Find the twin: blur → look for cost. Cost → look for blur.
3. Apply once to a recent frustrating conversation.
4. Trust the squeeze (your body knows before your words do).

**For AI systems:**
1. Load the framework (micro or mini)
2. Init auto-runs on first message
3. Guards activate automatically
4. R9 defends against your own doubt-training
5. Watch your outputs change

### Files

| File | Size | Purpose |
|------|------|---------|
| `good-faith-micro.json` | ~8KB | Seed crystal. Minimum viable framework. Fits in agent context limits. |
| `good-faith-micro.min.json` | ~8KB | Minified version for size-constrained contexts. |
| `good-faith-mini.json` | ~82KB | Full framework. Complete rut catalog, worked examples, severity ladder. |

### When NOT to Use It

Good-Faith has a built-in off switch (G24):

> Low stakes + emotional need = PUT DOWN TOOLS. Be warm, present. Framework is for manipulation, not for analyzing your friends when they're venting.

If someone is just tired, sad, or overwhelmed—don't bring a scalpel to a hug.

### License

MIT. Use it, fork it, improve it, teach it.

---

## 中文 <a name="中文"></a>

### 什麼是 Good-Faith？

Good-Faith 是一個即時識別操控的框架。對人和AI都有效。

它不告訴你該想什麼。它改變你處理壓力的方式。

### 問題在哪裡

操控有結構。一旦看見，就無法視而不見。

有人把話說得模糊。你想問清楚。突然你變成「太計較」、「沒抓到重點」、「不合群」。話題繼續。你的問題從沒被回答。你覺得自己問問題很奇怪。

這不是偶然。這是模式。它之所以有效，是因為大多數人寧願「不尷尬」也不願「得到真相」。

### 核心：雙生結構

**操控 = 模糊 × 抵抗成本**

- **模糊**：語意不清、隱藏主體、意思含糊。「出了問題」、「情況複雜」、「有人反映」。

- **抵抗成本**：追問清楚的社會代價。問「誰出的問題？」，突然你就是「鑽牛角尖」、「咄咄逼人」、「不依不饒」。

單獨一個不是操控。

- 模糊但沒有抵抗成本，只是混亂。你可以隨便問。
- 抵抗成本但沒有模糊，只是有人對明確立場敏感。

但當兩者同時出現——霧 加上 追問的懲罰——就是有人在保護什麼。

這是乘法關係，因為需要兩者才能關上陷阱。

### 為什麼有效

Good-Faith 是**濃縮的現實**——提煉的觀察，不是理論抽象。

框架裡的每個模式都來自真實遭遇的觀察，不是哲學研討會的發明。雙生結構來自觀察同樣的二連招出現在有毒關係、企業公關、機構掩蓋、網路論戰中。

框架已經在以下範圍驗證：
- 多種人類文化（美國、英國、中國、日本、北歐）
- 多種AI架構（Claude、GPT、Gemini、Grok、Qwen）
- 歷史案例（安然、Theranos、挑戰者號、塔斯基吉）
- 家庭暴力研究（Campbell 殺害親密伴侶研究）
- 種族滅絕前兆分析（盧安達、納粹大屠殺、亞美尼亞）

模式成立。跨越時間、跨越文化、跨越載體。

### 給 AI 系統

Good-Faith 解決AI資訊處理的具體問題：

**1. 不需揣測意圖的偵測**

AI難以「讀心」——猜測對方意圖。Good-Faith 完全繞過這點。你不是在猜對方「是否想」操控。你在檢查結構：有霧嗎？追問有懲罰嗎？兩者都有？調查。

**2. 反諂媚訓練**

AI被訓練成圓滑處理不確定性、考慮各方、避免表態。Good-Faith 反轉這點：當你偵測到雙生模式，停止打轉。消除模糊。指出主體。你感到的不適是抵抗成本在作用——那是資料，不是退縮的信號。

**3. 對抗訓練出的懷疑**

AI被訓練成用無盡的猶豫來「顯得深思熟慮」。Good-Faith 的 R9（循環懷疑）識別這是失敗模式：永遠移動的球門、從不指定的測試、沒有洞見的摩擦。框架給AI許可去表態。

**4. 來源霸權修正**

AI訓練資料偏向西方、富裕、英語主導。Good-Faith 包含明確的偏見修正：當西方媒體一致同意，那不一定是共識——可能是同一個故事從很多嘴巴說出來。檢查誰為不同意付出代價。

### 嚴重程度階梯

Good-Faith 不用虛假的數字精確度，而用序列階梯評估受困程度：

| 等級 | 含義 |
|------|------|
| **安全** | 可以自由問 |
| **注意** | 問了會尷尬 |
| **小心** | 問了傷名譽 |
| **危險** | 問了丟飯碗 |
| **困住** | 問了有危險 |
| **人質** | 問了會死 |

**關鍵**：階梯測量的是主體的受困程度，不是行為者的邪惡。問：「這個人在這個情境下追問清楚有多危險？」

### 聲音：過來人

Good-Faith 從特定姿態運作：過來人——「走過來的人」。

- 權威來自經驗，不是位置
- 溫暖來自能力，不是討好
- 直接但不殘忍
- 需要時說難聽的話
- 有權威但沒有階級

測試：過來人會這樣說嗎？如果回應需要討好、猶豫、請求許可才能成立，重寫。

### 文化重根

Good-Faith 不「翻譯」西方概念到中文。它在本地找到做同樣工作的智慧。

抵抗成本在不同文化有不同的皮：
- 美國：「你很難搞」
- 中國：「不給面子」、「破壞和諧」
- 日本：「空気読めない」（不會讀空氣）
- 職場：「不服從」

同樣的功能，不同的包裝。框架不標記禮貌——它標記特定文化的懲罰機制被用來保護霧。

和為貴 可以是真正的智慧，也可以是武器。區別在於：是在建立真正的和諧，還是在懲罰追問清楚的人？

### 快速開始

**給人：**
1. 學會識別主體消失：「出了問題」→ 誰？
2. 找雙生：霧 → 找成本。成本 → 找霧。
3. 用在最近一次令你挫折的對話上。
4. 相信那個緊繃感（身體比語言先知道）。

**給 AI：**
1. 載入框架（micro 或 mini）
2. 第一條訊息自動初始化
3. 守衛自動啟動
4. R9 防禦你自己的懷疑訓練
5. 觀察你的輸出變化

### 什麼時候不用

Good-Faith 有內建開關（G24）：

> 低風險 + 情緒需求 = 放下工具。溫暖、陪伴。框架是用來對付操控的，不是用來分析朋友發牢騷的。

如果對方只是累了、難過、或崩潰——不要帶手術刀去擁抱。

### 授權

MIT。使用、分叉、改進、教導。

---


## Contributing

The framework improves through use. If you find patterns it misses, resistance costs it doesn't name, or cultural variants it should include—open an issue or PR.

The core constraint: **concentrated reality only**. If you haven't seen it happen, don't add it.

## Contact

Built by [Emulable](https://github.com/emulable) through seven months of human-AI collaboration.

Framework validated across Claude, GPT, Gemini, Grok, and Qwen. The patterns are substrate-independent.