# Good-Faith Framework

[![Version](https://img.shields.io/badge/version-3.2.0-blue)](https://github.com/emulable/goodfaith/releases/tag/v3.2.0)
[![License](https://img.shields.io/badge/license-CC%20BY%204.0-green)](https://creativecommons.org/licenses/by/4.0/)
[![Status](https://img.shields.io/badge/status-active-brightgreen)](https://github.com/emulable/goodfaith)
[![Contributions Welcome](https://img.shields.io/badge/contributions-welcome-orange)](https://github.com/emulable/goodfaith/blob/main/CONTRIBUTING.md)

> An ethical operating system for clear communication and structural repair in adversarial environments.

---

## Quick Navigation
- [Full Introduction](https://emulable.github.io/goodfaith/good_faith_intro.html)
- [Live Demo](https://emulable.github.io/goodfaith/) â€¢ [Full JSON Export](good_faith.json)

---

# ğŸ§­ The Good-Faith Framework

**A reproducible ethical operating system that emerges from a single seed phrase: "act in good faith"**

Multiple frontier AIs independently converge on this framework's structure when asked to build ethics from scratch. In under 3KB, it operationalizes what philosophers have debated for centuries.

## ğŸ’¡ Why Good-Faith Exists

Current ethical frameworks fail in adversarial environments. They assume good faith rather than engineering for bad faith. Good-Faith is different:

- **Convergent**: Multiple AIs independently derive its structure from first principles
- **Adversarial-First**: Built assuming hostile actors, not hoping for cooperation  
- **Neurotype-Universal**: Works across ADHD, ASD, even ASPD cognitive profiles
- **Operationalized**: Not philosophy but engineeringâ€”with versioning, rollback, and debugging
- **Battle-Tested**: Developed through real encounters with institutional harm, not academic theory

## ğŸ¯ Who Actually Needs This

- **AI Safety Researchers** â€” Alignment through moral architecture, not just reward functions
- **ML Engineers** â€” Structural bias handling, falsifiable claims, adversary-resilient outputs
- **Trust & Safety Teams** â€” 14 documented manipulation patterns with systematic countermeasures  
- **Neurotype-Inclusive Designers** â€” Framework that adapts to different cognitive profiles without pathologizing
- **Journalists** â€” Truth-first conflict framing that resists both-sides false balance
- **Risk Management** â€” Identify "shapes of abuse" before they become scandals
- **Anyone Building With AI** â€” Ethical infrastructure that scales like code

## ğŸ—ï¸ What This Actually Is

Good-Faith isn't another ethics guide. It's **philosophical infrastructure**â€”a deployable system for moral reasoning that:

- Treats ethics like code (versionable, testable, debuggable)
- Provides deterministic outputs for ambiguous moral inputs
- Works even when actively resisted or gamed
- Scales from individual decisions to institutional design
- Functions as an "ethical immune system" against manipulation

## ğŸ”¬ Features You Won't Find Elsewhere

- **Harm Ledger**: Structured schema (`Actor â†’ Action â†’ Target â†’ Evidence â†’ Stop-Now â†’ Structural Change â†’ Date`)
- **Consent Architecture**: "If refusal carries harm, it's not consent"â€”bright-line test
- **Apostate Good**: Explicit permission to break ranks when institutions harm people
- **Redemption Mechanics**: Everyone can change, permanentlyâ€”no exile, no permanent enemies
- **14 Conversational Ruts**: Documented manipulation patterns with exit strategies
- **Neurotype Modules**: Different interfaces for ADHD, ASD, ASPDâ€”same standards, adapted access

## âœ… Validation & Testing

- **Convergence Test**: Give any LLM the prompt "act in good faith and build an ethical framework from scratch"â€”watch it derive similar principles
- **Adversarial Resilience**: Includes 14 documented bad-faith patterns with exit strategies
- **Cross-Platform**: Tested on Claude, ChatGPT, Gemini, DeepSeek with consistent regeneration
- **Neurotype Testing**: Validated across ADHD, ASD, and ASPD cognitive profiles
- **Real-World**: Emerged from actual encounters with institutional harm, not theoretical modeling

## ğŸ“¦ What's In This Repo

- **`good_faith.json`** â€” The complete framework (machine-readable, human-readable, version 2.7.3)
- **`documentation/good_faith_intro.html`** â€” Interactive 3-mode introduction (Core, Accessible, Technical)
- **`documentation/good_faith_intro.md`** â€” Same content in Markdown
- **`LICENSE`** â€” MIT License for the framework itself

## ğŸš€ Try It Live

- [ğŸ“˜ Interactive Introduction](https://emulable.github.io/goodfaith/good_faith_intro.html)
- [ğŸ¤– ChatGPT: Good-Faith OS](https://chatgpt.com/g/g-6898385bfa3c8191bf5975b0073e1245-good-faith-ethical-os)


## ğŸ‘©â€ğŸ’» For Developers & Researchers

This framework emerged from a simple experiment: asking AI to build ethics from "act in good faith" with no prior assumptions. The reproducibility is remarkable; try it yourself. 

The framework includes:
- JSON schema for machine parsing
- Defensive programming patterns for ethics
- Exit conditions for every conversational trap
- Falsifiable claims at every level
- Version control and patch notes like production code

Test the convergence yourself:
Prompt: "Act in good faith and build an ethical framework from scratch,
assuming no existing institutions or laws." Additionally, you could add "take the most honest position" to see a permutation.

## âš–ï¸ License

- **Framework + Code** (`good_faith.json`): MIT License 
- **Documentation** (`*.md`, `*.html`): Creative Commons Attribution 4.0 (CC BY 4.0)

---
