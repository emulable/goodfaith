

# üë∑ü©π‚ù§Ô∏è The Good-Faith Framework


**The Good-Faith Framework** is an ethical operating system designed for clarity and structural repair. It provides a set of precision-crafted tools for navigating complex situations by demanding honesty, consent, and measurable outcomes. Built for adversarial environments, it assumes some actors will be uncooperative and provides resilient protocols that function anyway. The framework's goal is to replace procedural theater with genuine repair and to equip users to identify and exit bad-faith interactions.



## ‚öñÔ∏è The Core Axioms


The framework is built on ten core axioms that function as a coherent logical system.


* üéØ **A0: Fidelity First ‚Äî ideas travel intact or not at all.**
This means you don't misrepresent a position or change the scope of a promise without explicitly saying so .


**Good Faith (Repair):** "We initially promised weekly delivery, but we have to change that to monthly. Here‚Äôs why that‚Äôs happening and how we‚Äôll adjust billing." 
**Bad Faith (Harm):** Silently updating a public roadmap to remove a promised feature, hoping no one notices the change .
* üö™ **A1: Consent means a safe no.**
For consent to be real, the person must be able to refuse without facing punishment or harm. It must be free, informed, and reversible .


**Good Faith (Repair):** A website allows you to reject non-essential cookies and still access all of its content .
**Bad Faith (Harm):** An employer tells an employee they can "choose" to work unpaid overtime, with the implied threat that refusing will hurt their career.
* üìù **A2: Say what‚Äôs true. Show what you know and where it ends.**
State facts clearly and be honest about the limits of your knowledge. Don't pad uncertainty with false confidence .


**Good Faith (Repair):** "Based on current data, we predict a 10% increase, but that forecast is uncertain due to market volatility."
**Bad Faith (Harm):** A manager, facing project delays, tells executives, "Everything's under control," without mentioning the known risks .
* üîß **A3: Repair means change.**
A genuine repair requires three things: naming the specific harm, stopping it immediately, and changing the underlying structure that allowed it to happen .


**Good Faith (Repair):** "Our reporting system had a bug that underpaid freelancers. We have stopped using that system, are issuing back-pay, and have implemented a new, audited payment structure." 
**Bad Faith (Harm):** A company apologizes for a data breach but makes no significant changes to its security, leading to another breach six months later .
* üö∂ **A4: People over systems (Apostate Good).**
Your loyalty belongs to human dignity, not to policies or institutions. If a rule is causing harm, your duty is to break ranks and fix it .


**Good Faith (Repair):** An employee escalates a customer issue that a "company policy" is making worse, documenting why the policy is harmful and needs an exception .
**Bad Faith (Harm):** A clerk tells a family in crisis, "Sorry, you're missing one form, so there's nothing I can do. It's company policy." 
* üß† **A5: No mind tricks. No self-harm aid.**
Refuse to use design or language to manipulate people's attention, create compulsion, or exploit psychological vulnerabilities. Never assist in self-harm .


**Good Faith (Repair):** A social media app offers clear, simple options to limit usage and disable notifications.
**Bad Faith (Harm):** A website designs a confusing, multi-step cancellation process with guilt-tripping language (a "dark pattern") to trick users into staying subscribed .
* üè† **A6: Boundaries build safety.**
Create clarity and reduce anxiety by stating limits, rules, and expectations upfront. Clear structure is the foundation of trust .


**Good Faith (Repair):** A project manager starts a meeting by saying, "We have 30 minutes. We'll decide on topic A, but topic B is out of scope for today." 
**Bad Faith (Harm):** A discussion with no clear agenda or moderation devolves into personal attacks and goes completely off-topic .
* üè∑Ô∏è **A7: Name things what they are.**
Avoid euphemisms that obscure reality and hide harm. Use literal, direct language .


**Good Faith (Repair):** A news report states, "Police shot and killed a man during the confrontation."
**Bad Faith (Harm):** A press release describes the same event as an "officer-involved shooting," using passive, agentless language to soften the reality .
* ‚è∞ **A8: Act on what you know.**
Don‚Äôt let the quest for perfect information paralyze you while harm continues. Ship a small, reversible fix now instead of waiting indefinitely .


**Good Faith (Repair):** Developers release a quick patch to fix a critical security bug, even if a more comprehensive update is planned for later .
**Bad Faith (Harm):** A company delays fixing a known product defect for months while it conducts "further analysis," allowing more customers to be affected .
* üèõÔ∏è **A9: Structural integrity over procedure.**
A framework or policy must produce just outcomes. If it follows all the procedural steps but still enables harm, it has failed .


**Good Faith (Repair):** A company scraps its "compliant" but ineffective harassment reporting system and replaces it with one that is survivor-centric and has real teeth .
**Bad Faith (Harm):** An organization defends a harmful outcome by saying, "We followed the process exactly as it's written in the handbook." 




## üõ†Ô∏è Key Operational Modules


The framework includes several modules that translate axioms into specific actions .


* **False Balance Breaker:** When harm is unequal, this module requires you to state it plainly ("Police inflicted most of the harm.") instead of using "both-sides" framing .
* **Provenance Lens:** This requires sources to be labeled by their class and incentive (e.g., "police press office," "advertiser-funded outlet") to make power dynamics transparent .
* **Harm Ledger:** A structured schema (`Actor ‚Üí Action ‚Üí Target ‚Üí Evidence ‚Üí Stop-Now ‚Üí Structural Change ‚Üí Date`) for recording harm forensically, preventing evasion through ambiguity .




## üöß The 14 Conversational Ruts


The framework provides a taxonomy of bad-faith dialogue patterns, or "ruts," along with exit scripts. They are a rhetorical self-defense manual for toxic conversations .


* **1. Burden-of-Proof Abuse:** This happens when someone demands endless evidence from you while providing none for their own claims . They perform curiosity to make you do all the work, often shifting the goalposts as you provide sources.
* **2. Headcount/Volume Pressure:** This tactic uses sheer quantity to overwhelm quality, either through a "pile-on" of multiple people repeating the same point or by one person making a dozen claims at once so none can be properly addressed .
* **3. Frame Coercion & Deflection:** This involves rigging the conversation by presenting a false binary ("If you don't support my solution, you must want the problem to continue") or deflecting from the topic by pointing to a different issue ("whataboutism") .
* **4. Claim Swap:** An arguer makes a bold, indefensible claim (the "bailey"), but when challenged, retreats to a much smaller, more reasonable one (the "motte") and pretends that was their point all along .
* **5. Authority/Prestige Shielding:** This is using one's role, credentials, or a vague appeal to "safety" or "policy" to shut down a discussion without addressing the substance of the issue . An example is locking a thread for being "unproductive" simply because the moderator is losing the argument.
* **6. Euphemism & Deniable Targeting:** This involves using soft, vague language to describe harsh actions (harm laundering) or using coded insults ("dogwhistles") to attack a person or group with plausible deniability .
* **7. Coercive Consent:** This is pressuring someone into agreement by making refusal unsafe or costly . It often involves false urgency ("You have to decide now!") or implied threats.
* **8. Stalling Instead of Trial:** This tactic avoids action by trapping the conversation in endless debate or procedural delays . The goal is to prevent a small, reversible test that could prove an idea right or wrong.
* **9. Low-Content Disruption:** This is poisoning a conversation with unproductive, low-effort contributions like sneering, mockery, or baiting questions designed to provoke rather than discuss .
* **10. Evidence & Record Tampering:** This involves dishonestly manipulating the conversational record, such as by selectively quoting someone out of context, or editing or deleting your own posts after they've been refuted to claim you never said them .
* **11. Credential Gatekeeping:** This is dismissing an argument by attacking the speaker's qualifications rather than engaging with the evidence they present . It‚Äôs an attempt to control who is allowed to speak on a topic.
* **12. Constraint Erasure:** This involves criticizing a decision by pretending that real-world constraints like time, budget, or the law don't exist . For example, "If you really cared, you would have rebuilt the entire system from scratch in two weeks."
* **13. Venue Control:** This is an attempt to move a conversation from a public, auditable space to a private one (like DMs) where the person has more control and can avoid accountability .
* **14. Emotional Gatekeeping:** This tactic makes engaging with facts conditional on providing emotional comfort to one party . It weaponizes feelings to stall or derail a conversation, such as, "I can't address your point until you say it in a way that doesn't make me feel attacked."





# üå±ü§ù‚ù§Ô∏è The Good-Faith Framework


**The Good-Faith Framework** is a toolkit for having honest conversations and fixing things that are broken. It's like a set of clear instructions for when things get messy‚Äîat work, online, or with family. Its main goal is simple: be honest, stop people from getting hurt, and actually make things better.


This framework was built for the real world, where not everyone plays fair. Its rules are designed to work even when someone is trying to bend the truth. It‚Äôs less about being *"nice"* and more about being truly fair.



## üëç The Basic Rules (and What Not To Do)


Here are the ten main rules, with examples of what they look like in action.


* üéØ **Rule 1: Don't twist words.**
Share ideas honestly. If you quote someone, share the whole story.


**Good Example:** "You said you'd be late, so I started the meeting without you."
**Bad Example:** Taking a text that says "I'm not sure, I might be late" and telling everyone "They said they're not coming."
* üö™ **Rule 2: A real choice means you can safely say "no."**
If saying "no" will get you in trouble, you aren't really free to choose.


**Good Example:** Your boss asks for volunteers for a weekend project and makes it clear it's okay if you can't.
**Bad Example:** Your boss asks for "volunteers," but everyone knows that the people who say no get the worst assignments next week.
* üìù **Rule 3: Be honest about what you don't know.**
It's okay to not have all the answers. Just say what you know for sure.


**Good Example:** "I know the power will be back on by 5 PM, but I'm not sure about the internet."
**Bad Example:** "Don't worry, everything will be totally back to normal by 5 PM!" (When you have no idea if that's true).
* üîß **Rule 4: Fixing things means changing things.**
Saying "sorry" isn't enough. You have to fix the problem so it doesn't happen again.


**Good Example:** Someone spills a drink on your floor, apologizes, cleans it up, and then buys a coaster so it won't happen again.
**Bad Example:** They say "oops, sorry," and then leave the spill for you to clean up.
* üö∂ **Rule 5: People are more important than rules.**
If a policy or rule is hurting someone, the right thing to do is challenge the rule.


**Good Example:** The library rule says "no food," but you see someone having a diabetic emergency and you run to get them a juice box from the cafe.
**Bad Example:** Sticking to the "no food" rule and refusing to help the person.
* üß† **Rule 6: No mind games.**
Don't try to trick or manipulate people.


**Good Example:** A website makes the "unsubscribe" button clear and easy to find.
**Bad Example:** A website hides the "unsubscribe" button behind five menus and tries to guilt you into staying.
* üè† **Rule 7: Clear boundaries make everyone feel safe.**
Let people know what to expect from the start.


**Good Example:** "We can talk about this for 10 more minutes, but then I have to go."
**Bad Example:** Letting a discussion drag on for an hour with no goal until everyone is tired and frustrated.
* üè∑Ô∏è **Rule 8: Call things what they are.**
Don't use fancy words to hide what's really happening.


**Good Example:** "I got fired from my job."
**Bad Example:** "My company and I are consciously uncoupling our professional partnership."
* ‚è∞ **Rule 9: If you see a problem, start fixing it.**
Don't wait for the "perfect" time to act while things are getting worse. A small fix now is better than a perfect fix that never happens.


**Good Example:** You see a leak in the roof, so you put a bucket under it right away while you call a roofer.
**Bad Example:** You decide to research all the best roofers in the country for two weeks while the leak ruins your floor.
* üèõÔ∏è **Rule 10: The process must actually work.**
It doesn't matter if you followed all the steps if the result is still bad.


**Good Example:** A school realizes its "official" anti-bullying program isn't working, so they throw it out and create a new one with student input.
**Bad Example:** The school keeps using the same failed program because "that's the official one we're supposed to use."




## üòí Conversation Traps to Avoid


This guide helps you spot when someone isn't arguing fairly. Here are 14 common traps, or "ruts."


* **1. The Proof Vampire:** They keep asking you for more and more proof for your ideas but never provide any for their own .
* **2. The Pile-On:** A bunch of people all jump in at once to make it seem like you're wrong because you're outnumbered .
* **3. The Subject Changer:** When you point out a problem, they immediately bring up something else to distract you ("What about that other thing?") .
* **4. The Claim Swapper:** They make a big, crazy claim. When you prove it wrong, they pretend they actually meant something much smaller and more reasonable .
* **5. The Rule-Book Shield:** They hide behind vague rules or their job title to avoid answering a real question ("As a manager, I can't discuss that") .
* **6. The Fancy Talker:** They use complicated words or coded insults to make something harmful sound okay or to attack someone without being obvious about it .
* **7. The Pressure Cooker:** They try to force you to agree by setting a fake deadline or hinting that something bad will happen if you say no .
* **8. The Endless Debater:** They just want to talk forever to avoid ever having to do anything. They prefer arguing about a problem to actually trying a solution .
* **9. The Troll:** They aren't interested in the conversation at all. They just post rude or silly comments to waste everyone's time and energy .
* **10. The History Editor:** They secretly edit their old comments after you've replied to them, trying to make it look like you're arguing against something they never said .
* **11. The Gatekeeper:** They say you're not "qualified" to have an opinion, focusing on who you are instead of what you're saying .
* **12. The Dreamer:** They criticize your choices by pretending you had unlimited time and money. They ignore all the real-world limits you were working with .
* **13. The Backroom Dealer:** They try to move a public argument into a private chat where they have more control and there are no witnesses .
* **14. The Emotional Tollbooth:** They refuse to talk about the facts until you've made them feel comfortable and happy. They use their feelings as a way to control the conversation .





# üèóÔ∏èüíªüõ°Ô∏è The Good-Faith Framework


**The Good-Faith Framework** is a deterministic ethical reasoning system designed to function as middleware in complex human and technical systems. It provides a set of non-negotiable constraints, data schemas, and protocols to ensure that operations maximize honesty, minimize preventable harm, and produce falsifiable, auditable outcomes. Architected for **adversarial environments**, it rejects *"assume good faith"* design patterns in favor of verifiable, resilient mechanisms that function under manipulative or uncooperative conditions.



## ‚öôÔ∏è The Axioms as a System Constraint API


The ten core axioms function as a validation layer or a set of system constraints. Each can be modeled as a function that returns a `PASS` or `FAIL` state.


* `A0_validate_fidelity(delta)`: **Fidelity First.**
**PASS:** A PR explicitly documents a change to a public-facing commitment in its description. `delta.is_declared == true`.
**FAIL:** A change to an API's behavior is deployed without being noted in the changelog. `ERROR: Silent scope creep detected`.
* `A1_validate_consent(choice)`: **Consent means a safe no.**
**PASS:** A user can decline tracking cookies, and `functionality_loss == 0`. The refusal penalty is zero.
**FAIL:** `refusal_penalty > 0`. A user who opts out of data collection is downgraded to a lower service tier. `ERROR: Coercive consent architecture`.
* `A2_validate_truth(claim)`: **Say what‚Äôs true, show where it ends.**
**PASS:** An incident report states, "We have confirmed the root cause was a database failure. The impact on other services is still under investigation." `claim.uncertainty.is_declared == true`.
**FAIL:** A status page says "All systems operational" when backend services are known to be degraded. `ERROR: False confidence padding`.
* `A3_validate_repair(action)`: **Repair means change.**
**PASS:** `action` includes `log_harm()`, `hotfix_deploy()`, and `deprecate_vulnerable_library()`. The structural vulnerability is removed.
**FAIL:** A public apology is issued for a service outage, but no infrastructure changes are made. `ERROR: No mechanism alteration`.
* `A4_validate_defection(action)`: **People over systems (Apostate Good).**
**PASS:** An engineer overrides an automated flagging system that is incorrectly blocking access for a legitimate user in crisis, and files a high-priority bug report.
**FAIL:** A support agent tells a user, "I can't help you, the system won't let me," when a manual override is possible. `ERROR: System loyalty over user dignity`.
* `A5_validate_design(pattern)`: **No mind tricks.**
**PASS:** The "delete account" process is a single, clearly labeled button.
**FAIL:** The unsubscribe flow requires navigating multiple pages with confusing language. `ERROR: Dark pattern detected`.
* `A6_validate_boundaries(interaction)`: **Boundaries build safety.**
**PASS:** An API contract is strictly versioned, and all endpoints have clearly defined rate limits.
**FAIL:** A meeting has no agenda, no specified end time, and no clear decision-making process. `ERROR: Undefined operational boundaries`.
* `A7_validate_language(string)`: **Name things plainly.**
**PASS:** A commit message reads: "Refactor billing module to fix race condition causing overcharging."
**FAIL:** A press release describes mass layoffs as a "strategic workforce realignment." `ERROR: Euphemism detected (harm laundering)`.
* `A8_validate_action(response)`: **Act on what you know.**
**PASS:** A CVE is announced, and a temporary firewall rule is immediately pushed to mitigate the risk while a full patch is developed. `response.includes_immediate_mitigation == true`.
**FAIL:** A security team decides to wait for the next quarterly patching cycle to address a known vulnerability. `ERROR: Stalling while harm continues`.
* `A9_validate_integrity(system)`: **Structural integrity over procedure.**
**PASS:** An audit reveals that a "fully compliant" data retention policy is causing unnecessary user harm, so the policy is rewritten.
**FAIL:** A system that passes all unit tests is still deployed despite QA finding that it creates a hostile user experience. `ERROR: Compliance without harm reduction`.




## ‚ò£Ô∏è The 14 Ruts as Attack Vectors


The conversational ruts are a taxonomy of social engineering and denial-of-service attacks against reasoned discourse. Understanding them is critical for building resilient sociotechnical systems.


* **1. Burden-of-Proof Abuse (Resource Exhaustion Attack):** The attacker forces the target to expend significant computational resources (research, citation) by making low-cost, un-evidenced demands, analogous to a DDoS attack on a person's time and energy .
* **2. Headcount/Volume Pressure (Sybil Attack):** This attack uses a flood of low-quality inputs (many claims) or seemingly independent actors (a "brigade") to create a false consensus and overwhelm the target's ability to process and respond to each claim individually .
* **3. Frame Coercion & Deflection (Input Manipulation):** The attacker attempts to control the operational space by providing malicious input‚Äîa false binary that restricts valid options‚Äîor triggers a context switch (deflection) to a different problem to evade local accountability .
* **4. Claim Swap (State Inconsistency Attack):** The attacker exploits ambiguity by making a strong claim and, upon invalidation, reverting to a weaker, previously valid state (the "motte"), causing confusion about the system's current set of assertions .
* **5. Authority/Prestige Shielding (Privilege Escalation):** An attacker uses their role or status as an authentication token to bypass normal validation checks for their claims, demanding their assertions be accepted without the required evidence .
* **6. Euphemism & Deniable Targeting (Obfuscation/Side-Channel Attack):** This involves using obfuscated language (euphemisms) to hide the true nature of a harmful action, or using coded language (dogwhistles) to transmit a malicious payload to a target audience while maintaining deniability .
* **7. Coercive Consent (Protocol-Level Exploit):** The attacker exploits the consent protocol by creating a condition where refusal (a `NO` response) results in a penalty, effectively turning a supposedly free choice into a forced one .
* **8. Stalling Instead of Trial (Livelock/Denial of Service):** The system is kept in a state of endless debate or process, preventing it from moving to a resolution or action state. This is a denial-of-service attack on progress .
* **9. Low-Content Disruption (Packet Flooding/Spam):** This attack injects low-signal, high-noise data into the communication channel (e.g., sneering, baiting) to degrade the quality of the conversation and exhaust the patience of legitimate participants .
* **10. Evidence & Record Tampering (Log Manipulation):** An attack on the system's audit trail. It involves altering or deleting records of prior states (editing posts, deleting comments) to invalidate subsequent actions or rebuttals that depend on that history .
* **11. Credential Gatekeeping (Authentication/Authorization Attack):** This attack invalidates a user's input not based on its content but on the user's lack of a specific attribute (e.g., a credential), improperly using authentication to gatekeep authorization to speak .
* **12. Constraint Erasure (Invalid Test Environment):** The attacker evaluates a system's output as if it were operating in an ideal environment with infinite resources (time, money, etc.), leading to bad-faith critiques that ignore necessary trade-offs .
* **13. Venue Control (Man-in-the-Middle Attack):** The attacker moves the communication from a trusted, public channel to a private one they control, allowing them to manipulate the conversation's flow, visibility, and record without oversight .
* **14. Emotional Gatekeeping (Request Smuggling/DoS):** The attacker embeds a non-functional requirement (provide emotional comfort) within a functional request (address this evidence). This can stall the primary request indefinitely, a denial-of-service attack on factual accountability .




